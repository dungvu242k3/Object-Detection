# -*- coding: utf-8 -*-
"""Faster_R-CNN_fruitImage.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1m5EH0oexJsqUkCc1dHCR8UsRIV1zyTft
"""

import os
import xml.etree.ElementTree as ET
import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from torchvision.models.detection import fasterrcnn_resnet50_fpn, FasterRCNN_ResNet50_FPN_Weights
from PIL import Image
from google.colab import drive
import matplotlib.pyplot as plt
import matplotlib.patches as patches
import numpy as np

drive.mount('/content/drive')

!unzip /content/drive/MyDrive/data/train_zip.zip -d /content/train
!unzip /content/drive/MyDrive/data/test_zip.zip -d /content/test

class FruitDataset(Dataset):
    def __init__(self, image_paths, annotation_paths, transform=None):
        self.image_paths = image_paths
        self.annotation_paths = annotation_paths
        self.transform = transform

        self.label_map = {"apple": 1, "banana": 2, "orange": 3}

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        image = Image.open(self.image_paths[idx]).convert("RGB")
        annotation = ET.parse(self.annotation_paths[idx]).getroot()

        boxes = []
        labels = []

        for obj in annotation.findall("object"):
            name = obj.find("name").text.lower()
            label = self.label_map[name]

            bbox = obj.find("bndbox")
            xmin = float(bbox.find("xmin").text)
            ymin = float(bbox.find("ymin").text)
            xmax = float(bbox.find("xmax").text)
            ymax = float(bbox.find("ymax").text)
            boxes.append([xmin, ymin, xmax, ymax])
            labels.append(label)

        boxes = torch.tensor(boxes, dtype=torch.float32)
        labels = torch.tensor(labels, dtype=torch.int64)

        target = {
            "boxes": boxes,
            "labels": labels,
        }

        if self.transform:
            image = self.transform(image)

        return image, target

def get_file_paths(root_path):
    files = os.listdir(root_path)
    image_paths = [os.path.join(root_path, f) for f in files if f.endswith('.jpg')]
    annotation_paths = [os.path.join(root_path, f.replace('.jpg','.xml')) for f in files if f.endswith('.jpg')]
    return image_paths, annotation_paths

def visualize_predictions(image, boxes, labels, scores, label_map, threshold=0.5):
    fig, ax = plt.subplots(1, figsize=(12,9))
    ax.imshow(image)
    for box, label, score in zip(boxes, labels, scores):
        if score > threshold:
            x1, y1, x2, y2 = box
            rect = patches.Rectangle((x1, y1), x2-x1, y2-y1,linewidth=2, edgecolor='r', facecolor='none')
            ax.add_patch(rect)
            ax.text(x1, y1, f"{label_map.get(label, 'Unknown')}: {score:.2f}",
                    bbox=dict(facecolor='red', alpha=0.5), color='white')
    plt.axis('off')
    plt.show()

train_images, train_annotations = get_file_paths("/content/train/train_zip/train")
test_images, test_annotations = get_file_paths("/content/test/test_zip/test")

transform = transforms.Compose([
    transforms.ToTensor(),
])

train_dataset = FruitDataset(train_images, train_annotations, transform=transform)
test_dataset = FruitDataset(test_images, test_annotations, transform=transform)

train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))
test_loader = DataLoader(test_dataset, batch_size=4, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = fasterrcnn_resnet50_fpn(weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT).to(device)
model.train()
params = [p for p in model.parameters() if p.requires_grad]
optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)

for epoch in range(1):
    model.train()
    total_loss = 0
    for images, targets in train_loader:
        images = list(img.to(device) for img in images)
        targets = [{k: v.to(device) for k,v in t.items()} for t in targets]

        loss_dict = model(images, targets)
        losses = sum(loss for loss in loss_dict.values())

        optimizer.zero_grad()
        losses.backward()
        optimizer.step()

        total_loss += losses.item()

    print(f"Epoch {epoch+1}, Loss: {total_loss/len(train_loader)}")

label_map = {1:"apple", 2:"banana", 3:"orange"}

max_images = 5
model.eval()
for i in range(min(len(test_images), max_images)):
    test_img_path = test_images[i]
    test_img = Image.open(test_img_path).convert("RGB")
    test_img_tensor = transform(test_img).to(device)

    with torch.no_grad():
        prediction = model([test_img_tensor])[0]

    boxes = prediction['boxes'].cpu().numpy()
    labels = prediction['labels'].cpu().numpy()
    scores = prediction['scores'].cpu().numpy()


    visualize_predictions(np.array(test_img), boxes, labels, scores, label_map)
